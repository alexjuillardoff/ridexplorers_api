# üé¢ RIDEXPLORERS API

RIDEXPLORERS API fournit une API REST simple contenant des donn√©es r√©cup√©r√©es sur [RCDB](https://rcdb.com). Elle est construite en **TypeScript** avec **Express** et expose des points d'entr√©es pour interroger les montagnes russes et les parcs d'attractions. Une documentation g√©n√©r√©e √† partir de la sp√©cification OpenAPI est disponible sur `/docs` lorsque le serveur est lanc√©.

## Fonctionnalit√©s

- Interrogation des montagnes russes et des parcs d'attractions via des routes REST.
- Recherche de montagnes russes ou de parcs par nom.
- S√©lection al√©atoire de montagnes russes pr√©alablement scrapp√©es.
- Obtention d'une montagne russe al√©atoire.
- Lancement et suivi des scripts de scraping depuis l'API ou l'interface web.
- T√©l√©versement et lecture de fichiers JSON de donn√©es.
- Authentification Basic configur√©e par variables d'environnement.
- Consentement aux cookies conforme RGPD via l'endpoint `/cookies/consent` et une banni√®re d'information.

Ce projet n√©cessite **Node.js 18** ou plus r√©cent.

---

## Pr√©requis

- Option 1 - Installation locale Node.js: Node 18+ et npm.
- Option 2 - Installation via Docker: Docker Desktop 4.0+.

---

## D√©marrage rapide (installation locale Node.js)

1. Installer les d√©pendances
   ```bash
   npm install
   ```
2. Construire le projet
   ```bash
   npm run build
   ```
3. Lancer l'API
   - D√©veloppement: recompilation et rechargement automatiques via `nodemon`.
     ```bash
     npm run start:dev
     ```
   - Production: ex√©cute le JavaScript compil√© depuis `dist/`.
     ```bash
     npm run start:prod
     ```

### Variables d'environnement

Le serveur lit plusieurs variables facultatives dans un fichier `.env`. Ces variables sont charg√©es automatiquement au d√©marrage gr√¢ce √† `dotenv`.

- `PORT` - port sur lequel l'API sera accessible (d√©faut: `8000`).
- `RCDB_URL` - URL de base utilis√©e pour le scraping de RCDB (d√©faut: `https://rcdb.com`).
- `AUTH_USER` - nom d'utilisateur pour l'authentification Basic.
- `AUTH_PASSWORD` - mot de passe associ√©.

Un fichier `.env.example` est fourni. Dupliquez-le en `.env` et adaptez les valeurs.

---

## Installation et ex√©cution via Docker (recommand√©)

Le d√©p√¥t contient une stack Docker pr√™te √† l'emploi:

- `Dockerfile` - build multi-stage Node 20.
- `docker-compose.yml` - services `api`, `nginx` (reverse proxy) et `scraper` (automatisation).
- `nginx/nginx.conf` - reverse proxy HTTP vers l'API, avec taille d'upload √©tendue.
- `scraper/run.sh` - planificateur de scraping avec d√©lai al√©atoire.

### Lancer l'API derri√®re Nginx

1. Copier la configuration d'environnement
   ```bash
   cp .env.example .env
   ```
2. D√©marrer la stack
   ```bash
   docker compose up -d
   ```
3. V√©rifier
   - API: `http://localhost/api`
   - Docs OpenAPI: `http://localhost/docs`

### Scraping manuel dans l'image Docker

Les scripts TypeScript sont compil√©s en JavaScript dans `dist/`. Ex√©cutez-les depuis le conteneur `api`.

- Coasters par plage d'IDs
  ```bash
  docker compose exec api node dist/scraping/main.js --startId 0 --endId 1000 --saveData true
  ```
- Mapping des photos
  ```bash
  docker compose exec api node dist/scraping/map-coaster-photos.js --startId 0 --endId 1000 --saveData true
  ```
- Parcs d'attractions
  ```bash
  docker compose exec api node dist/scraping/scrape-theme-parks.js
  ```
- √âchantillon al√©atoire
  ```bash
  docker compose exec api node dist/scraping/scrape-random-coasters.js
  ```

Les fichiers JSON sont persist√©s dans `src/db/` via un volume Docker.

### Automatisation du scraping (service `scraper`)

Un service `scraper` lance p√©riodiquement des runs avec un d√©lai al√©atoire entre 24 h et 48 h pour limiter les blocages.

- D√©marrer le planificateur
  ```bash
  docker compose up -d scraper
  docker compose logs -f scraper
  ```
- Variables ajustables (dans `docker-compose.yml` ou via `env_file`)
  - `MAX_ID` - borne max des IDs coasters (d√©faut: `25000`).
  - `BATCH` - taille du lot par run (d√©faut: `1500`).
  - `WAIT_MIN_HOURS` - attente minimale entre 2 runs (d√©faut: `24`).
  - `WAIT_MAX_HOURS` - attente maximale entre 2 runs (d√©faut: `48`).
  - `PAUSE_MIN_SEC` - pause minimale entre √©tapes d'un run (d√©faut: `10`).
  - `PAUSE_MAX_SEC` - pause maximale entre √©tapes d'un run (d√©faut: `45`).
  - `RETRIES` - tentatives par √©tape en cas d'√©chec (d√©faut: `3`).

- Test d'un cycle imm√©diat (one-shot)
  ```bash
  docker compose run --rm \
    -e ONE_SHOT=1 \
    -e WAIT_MIN_HOURS=0 -e WAIT_MAX_HOURS=0 \
    -e PAUSE_MIN_SEC=1 -e PAUSE_MAX_SEC=3 \
    scraper
  ```

Le script `scraper/run.sh` ex√©cute, dans cet ordre, un lot de coasters, le mapping des photos, et al√©atoirement un refresh des parcs et un √©chantillon al√©atoire. Un fichier `.last-scrape` est √©crit dans `src/db/` avec l'horodatage du dernier passage.

### Exposition externe

- Redirection de port sur votre routeur vers le port 80 du Mac qui h√©berge Docker.
- Pour HTTPS, ajoutez un certificat et la configuration TLS √† `nginx/nginx.conf` ou utilisez un conteneur compagnon pour Let's Encrypt.

---

## Scraping des donn√©es (installation locale)

L'API fonctionne avec des fichiers JSON situ√©s dans `src/db/`. Ces fichiers sont g√©n√©r√©s en scrappant RCDB. Plusieurs scripts npm sont fournis.

- `npm run scrape` - r√©cup√®re les montagnes russes depuis RCDB. Options `--startId`/`--endId` ou `--startPage`/`--endPage`. Les donn√©es brutes sont enregistr√©es dans `src/db/coasters-raw.json` puis, si `--saveData` vaut `true`, dans `src/db/coasters.json`.
- `npm run scrape:theme-parks` - r√©cup√®re les informations des parcs et les sauvegarde dans `src/db/theme-parks.json`.
- `npm run scrape:map-coaster-photos` - associe les URL d'images des montagnes russes d√©j√† r√©cup√©r√©es avec l'URL de base configur√©e.
- `npm run scrape:random` - r√©cup√®re un √©chantillon al√©atoire de montagnes russes et le stocke dans `src/db/random-coasters.json`.

Ces scripts t√©l√©chargent les pages RCDB via `axios`, extraient les donn√©es avec `cheerio` et √©crivent les fichiers JSON dans `src/db/`. Ils peuvent aussi √™tre d√©clench√©s via l'interface web qui communique avec un service d√©marrant les scripts npm et diffusant les logs en temps r√©el.

### Routes de gestion des fichiers de scraping

- `GET /scrape/files` - liste les fichiers JSON extraits disponibles.
- `GET /scrape/files/:name` - r√©cup√®re le contenu d'un fichier de scraping.
- `POST /scrape/upload` - charge manuellement un fichier JSON dans `src/db/` (jusqu'√† 1 Go). Envoyez le fichier au format `multipart/form-data`.

> Remarque: l'URL RCDB par d√©faut est `https://rcdb.com` et peut √™tre modifi√©e via `RCDB_URL`.

---

## Endpoints

| Verbe HTTP | Chemin                          | Description |
| --------- | ------------------------------- | ----------- |
| `GET`     | `/` ou `/api`                   | Liste des endpoints disponibles |
| `GET`     | `/api/coasters`                 | Liste pagin√©e de montagnes russes. Param√®tres `offset` et `limit`. |
| `GET`     | `/api/coasters/:id`             | Montagne russe par id. `404` si non trouv√©e. |
| `GET`     | `/api/coasters/random`          | Montagne russe al√©atoire. |
| `GET`     | `/api/coasters/search?q=`       | Recherche par nom de montagne russe ou de parc. |
| `GET`     | `/api/coasters/region/{region}` | Montagnes russes d'une r√©gion. |
| `GET`     | `/api/coasters/filter`          | Filtre par caract√©ristiques via query params. |
| `GET`     | `/api/theme-parks`              | Liste pagin√©e des parcs. Param√®tres `offset` et `limit`. |
| `GET`     | `/api/theme-parks/:id`          | Parc par id. `400` si non trouv√©. |
| `GET`     | `/api/theme-parks/search?q=`    | Recherche de parcs par nom. |
| `GET`     | `/api/theme-parks/region/{region}` | Parcs d'une r√©gion. |
| `GET`     | `/scrape/files`                 | Liste des fichiers JSON disponibles. |
| `GET`     | `/scrape/files/:name`           | R√©cup√®re le contenu d'un fichier de scraping. |
| `POST`    | `/scrape/upload`                | T√©l√©verse un fichier JSON (<= 1 Go) sur le serveur. |

---

## Fichiers de donn√©es

- `src/db/coasters.json` - toutes les montagnes russes scrapp√©es avec leurs images mapp√©es.
- `src/db/coasters-raw.json` - donn√©es brutes avant le mapping des images.
- `src/db/theme-parks.json` - donn√©es extraites des parcs d'attractions.
- `src/db/random-coasters.json` - √©chantillon al√©atoire obtenu via `scrape:random`.
- `src/db/.last-scrape` - horodatage du dernier passage de l'automatisation.

---

## Structure du d√©p√¥t

```text
.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf
‚îú‚îÄ‚îÄ scraper/
‚îÇ   ‚îî‚îÄ‚îÄ run.sh
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ db/
‚îÇ       ‚îî‚îÄ‚îÄ .gitkeep
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄ README.md
```

---

## S√©curit√© et bonnes pratiques

- Activez l'authentification Basic via `AUTH_USER` et `AUTH_PASSWORD` si l'API est expos√©e.
- N'exposez que le reverse proxy Nginx. Laissez l'API en r√©seau interne Docker.
- Surveillez la taille du dossier `src/db/` et archivez r√©guli√®rement si n√©cessaire.
- Ne poussez jamais de donn√©es r√©elles ni de secrets. Utilisez `.env.example` pour documenter les variables.

Bonne visite et bons rides !

