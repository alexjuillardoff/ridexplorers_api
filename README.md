# ðŸŽ¢ RIDEXPLORERS API

RIDEXPLORERS API exposes a simple REST API containing data scraped from [RCDB](https://rcdb.com). It is built with **TypeScript** using **Express** and provides endpoints to query roller coasters and theme parks information. Documentation generated from the OpenAPI specification is available at `/docs` when the server is running.

This project requires **Node.js 18** or later.

## Getting started

1. **Install dependencies**
   ```bash
   npm install
   ```
2. **Build the project**
   ```bash
   npm run build
   ```
3. **Start the API**
   - Development: automatically recompiles and reloads using `nodemon`.
     ```bash
     npm run start:dev
     ```
   - Production: run the compiled JavaScript from `dist/`.
     ```bash
    npm run start:prod
    ```

### Environment variables

The server reads several optional variables from a `.env` file:

- `PORT` â€“ port where the API will listen (defaults to `8000`).
- `RCDB_URL` â€“ base URL used when scraping data from RCDB.


### Scraping data
The API works with JSON files located under `src/db/`. These files are generated by scraping RCDB. Several npm scripts are provided:

- `npm run scrape` â€“ scrape coaster data between a range of IDs or pages and store it inside `src/db/coasters.json`. Images are mapped to an absolute URL with `scrape:map-coaster-photos`.
- `npm run scrape:theme-parks` â€“ scrape theme park information and save it to `src/db/theme-parks.json`.
- `npm run scrape:random` â€“ scrape a random set of coasters and store them in `src/db/random-coasters.json`.
- `npm run scrape:map-coaster-photos` â€“ map image URLs of previously scraped coasters to the configured RCDB base URL.

Scraping tasks can also be controlled at runtime using the following HTTP routes:

- `GET /scrape/start?script=<name>` â€“ launch one of the npm scraping scripts.
- `POST /scrape/cancel` â€“ cancel the currently running scraping task.
- `GET /scrape/tasks` â€“ list executed scraping tasks and their status.
- `GET /scrape/logs?id=<taskId>` â€“ retrieve logs for a given task (defaults to the active one).
- `GET /scrape/files` â€“ list available scraped JSON files.
- `GET /scrape/files/:name` â€“ retrieve the content of a scraped file.
- `POST /scrape/upload` â€“ manually upload a JSON file to `src/db/`.

> **Note**: by default the RCDB base URL is `https://rcdb.com`. You can override it by setting the `RCDB_URL` environment variable.

## Endpoints

| HTTP Verb | Path                       | Description                                                                                      |
| --------- | -------------------------- | ------------------------------------------------------------------------------------------------ |
| `GET`     | `/` or `/api`              | List of available endpoints.                                                                     |
| `GET`     | `/api/coasters`            | Returns a paginated list of coasters. Use `offset` and `limit` query parameters.                 |
| `GET`     | `/api/coasters/:id`        | Returns coaster information by id. Returns `404` if not found.                                   |
| `GET`     | `/api/random-coasters`     | Returns the list of coasters scraped with `scrape:random`.                   |
| `GET`     | `/api/coasters/search?q=`  | Returns coasters whose name or park matches the `q` value.                                       |
| `GET`     | `/api/theme-parks`         | Returns a paginated list of theme parks. Use `offset` and `limit` query parameters.              |
| `GET`     | `/api/theme-parks/:id`     | Returns a theme park by id. Returns `400` if not found.                                          |
| `GET`     | `/scrape/start`            | Start a scraping script specified via the `script` query param.                                  |
| `POST`    | `/scrape/cancel`           | Cancel the currently running scraping task.                                                     |
| `GET`     | `/scrape/tasks`            | List all scraping tasks with their status.                                                      |
| `GET`     | `/scrape/logs`             | Retrieve logs for the active task or the one specified by `id`.                                |
| `GET`     | `/scrape/files`            | List available scraped JSON files.                                                              |
| `GET`     | `/scrape/files/:name`      | Retrieve the content of a scraped file. |
| `POST`    | `/scrape/upload`           | Upload a JSON file to the server. |
| `GET`     | `/explorer.html`           | Web interface to browse and manage files under `src/db`. |
| `ANY`     | `/connector`               | elFinder connector providing file operations for the explorer. |


## File Explorer
A web interface using `elFinder` is available at [`/explorer.html`](./explorer.html). It allows browsing and managing the JSON files in `src/db` via the `/connector` endpoint.

## Data files
- `src/db/coasters.json` â€“ all scraped coasters with mapped image URLs.
- `src/db/coasters-raw.json` â€“ raw coaster data before mapping images.
- `src/db/theme-parks.json` â€“ scraped theme park data.
- `src/db/random-coasters.json` â€“ results from `npm run scrape:random`.

Happy riding!
